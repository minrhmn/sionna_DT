{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5913a368-2fb6-4523-b56e-1e00c2175aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751208912.142759   80090 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751208912.145454   80090 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751208912.152860   80090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751208912.152873   80090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751208912.152874   80090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751208912.152875   80090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "# Set some environment variables\n",
    "import os\n",
    "gpu_num = 0 # GPU to be used. Use \"\" to use the CPU\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Suppress some TF warnings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna\n",
    "\n",
    "# Configure GPU\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Avoid warnings from TensorFlow\n",
    "import warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fix the seed for reproducible results\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696f76c0-c6b9-4433-941d-e4c43d1627d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 18:03:25.777442: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-30 18:03:25.785876: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751321005.795342    8917 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751321005.798196    8917 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751321005.806032    8917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751321005.806050    8917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751321005.806051    8917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751321005.806052    8917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-30 18:03:25.808792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import Sionna RT components\n",
    "from sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, Camera, PathSolver, RadioMapSolver, subcarrier_frequencies\n",
    "\n",
    "# For link-level simulations\n",
    "from sionna.phy import mapping,ofdm,utils\n",
    "from sionna.phy.channel import cir_to_ofdm_channel, subcarrier_frequencies, OFDMChannel, ApplyOFDMChannel, CIRDataset, AWGN\n",
    "from sionna.phy.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\n",
    "from sionna.phy.utils import compute_ber, ebnodb2no, PlotBER\n",
    "from sionna.phy.ofdm import KBestDetector, LinearDetector, ResourceGrid\n",
    "from sionna.phy.mapping import Constellation, Mapper, Demapper\n",
    "from sionna.phy.fec.polar import PolarEncoder, Polar5GEncoder, PolarSCLDecoder, Polar5GDecoder, PolarSCDecoder\n",
    "from sionna.phy.fec.ldpc import LDPC5GEncoder, LDPC5GDecoder\n",
    "from sionna.phy.fec.polar.utils import generate_5g_ranking, generate_rm_code\n",
    "from sionna.phy.fec.conv import ConvEncoder, ViterbiDecoder, BCJRDecoder\n",
    "from sionna.phy.fec.turbo import TurboEncoder, TurboDecoder\n",
    "from sionna.phy.fec.linear import OSDecoder\n",
    "from sionna.phy.mapping import BinarySource\n",
    "from sionna.phy.utils.metrics import  count_block_errors\n",
    "from sionna.phy.mimo import StreamManagement\n",
    "import mitsuba\n",
    "\n",
    "import scipy.special as sp\n",
    "import scipy.stats as stats\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "no_preview = False # Toggle to False to use the preview widget\n",
    "                  # instead of rendering for scene visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07177dd1-0431-48a9-a66c-fba8753ddec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scene = load_scene(sionna.rt.scene.munich, merge_shapes=True) # Merge /home/minhaj/weeks_hallshapes to speed-up computations\n",
    "scene = load_scene('/home/minhaj/weeks_hall_final/weeks_hall_final.xml', merge_shapes=False)\n",
    "#scene.objects\n",
    "#scene.radio_materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c44491fa-b677-406e-a443-e2a8e0409437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System parameters\n",
    "subcarrier_spacing = 30e3 # Hz\n",
    "num_time_steps = 14 # Total number of ofdm symbols per slot\n",
    "\n",
    "num_tx = 1 # Number of users\n",
    "num_rx = 1 # Only one receiver considered\n",
    "num_tx_ant = 1 # Each user has 4 antennas\n",
    "num_rx_ant = 1 # The receiver is equipped with 16 antennas\n",
    "\n",
    "# batch_size for CIR generation\n",
    "batch_size_cir = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc5c2d3d-1d16-4ed7-9779-309dc4fd2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure antenna array for all transmitters\n",
    "scene.tx_array = PlanarArray(num_rows=1,\n",
    "                             num_cols=1,\n",
    "                             vertical_spacing=0,\n",
    "                             horizontal_spacing=0,\n",
    "                             pattern=\"iso\",\n",
    "                             polarization=\"V\")\n",
    "\n",
    "\n",
    "# Create transmitter\n",
    "tx = Transmitter(name=\"tx\",\n",
    "                 position=[-1.4,2.2,1.1],\n",
    "                 display_radius=0.3)\n",
    "\n",
    "# Add transmitter instance to scene\n",
    "scene.add(tx)\n",
    "\n",
    "\n",
    "bird_cam = Camera(position=[-1.5,0,25], orientation=np.array([0,np.pi/2,-np.pi/2]))\n",
    "#scene.preview();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b99b2793-fe0d-4a97-a0bd-d0a51dd8df04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a64fe2562246898fd0ef60324f24c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Renderer(camera=PerspectiveCamera(aspect=1.31, children=(DirectionalLight(intensity=0.25, posit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the radio map center (elevation control)\n",
    "center = mitsuba.Point3f(0, 0, 0.2)  # 2.0 meters for the radio map center\n",
    "\n",
    "# Define the orientation (optional, if you want to tilt the radio map)\n",
    "orientation = mitsuba.Point3f(0, 0, 0)  # Adjust angles as needed\n",
    "\n",
    "# Define the size of the radio map (covering the entire scene)\n",
    "size = mitsuba.Point2f(100, 100)  # Adjust size to focus on the area of interest\n",
    "\n",
    "# Define cell size (resolution of the radio map)\n",
    "cell_size = mitsuba.Point2f(0.1, 0.1)  # Size of each cell in the grid\n",
    "\n",
    "# Set the number of samples per transmitter (more samples = higher accuracy)\n",
    "samples_per_tx = 10000000\n",
    "\n",
    "# Set the max depth (for path tracing)\n",
    "max_depth = 2\n",
    "\n",
    "# Configure the radio map solver\n",
    "rm_solver = RadioMapSolver()\n",
    "\n",
    "# Compute the radio map with the new parameters\n",
    "rm = rm_solver(scene,\n",
    "               center=center,\n",
    "               orientation=orientation,\n",
    "               size=size,\n",
    "               cell_size=cell_size,\n",
    "               samples_per_tx=samples_per_tx,\n",
    "               max_depth=max_depth)\n",
    "\n",
    "# Optional: Render the radio map from the bird's eye view\n",
    "bird_cam = Camera(position=[-1.5, 0, 25], orientation=np.array([0, np.pi/2, -np.pi/2]))\n",
    "\n",
    "scene.preview(radio_map=rm,\n",
    "              rm_vmin=-90,\n",
    "              clip_at=3.); # Clip the scene at rendering for visualizing the refracted field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ab55c-ac14-4cc5-8947-80f96290020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['font.family']       = 'serif'\n",
    "mpl.rcParams['font.serif']        = ['Times New Roman']\n",
    "mpl.rcParams['font.size']         = 16\n",
    "\n",
    "fig = scene.render(\n",
    "    camera=bird_cam,\n",
    "    radio_map=rm,\n",
    "    rm_vmin=-80,\n",
    "    rm_show_color_bar=True,\n",
    "    clip_at=3,\n",
    "    resolution=(1024,768),\n",
    "    num_samples=512\n",
    ")\n",
    "\n",
    "# assume the colorbar was drawn as the last axes in the figure\n",
    "cbar_ax = fig.axes[-1]\n",
    "cbar_ax.set_ylabel(\"Path Gain (dB)\", fontsize=18, fontweight=\"bold\")\n",
    "\n",
    "fig.savefig(\"radio_map.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02f21acf-dfa4-4d4e-aa01-3b9d343ebc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 3\n",
    "\n",
    "# Radio map solver\n",
    "rm_solver = RadioMapSolver()\n",
    "\n",
    "# Compute the radio map\n",
    "rm = rm_solver(scene,\n",
    "               max_depth=5,\n",
    "               cell_size=(0.1, 0.1),\n",
    "               samples_per_tx=10**7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0974ea5-f032-438a-b9d8-df0b08923e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52519a7a50ca4508b7359ab4bb1ce971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Renderer(camera=PerspectiveCamera(aspect=1.31, children=(DirectionalLight(intensity=0.25, matri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if no_preview:\n",
    "    # Render an image\n",
    "    scene.render(camera=bird_cam,\n",
    "                 radio_map=rm,\n",
    "                 rm_vmin=-110,\n",
    "                 clip_at=2.); # Clip the scene at rendering for visualizing the refracted field\n",
    "else:\n",
    "    # Show preview\n",
    "    scene.preview(radio_map=rm,\n",
    "                  rm_vmin=-110,\n",
    "                  clip_at=3.); # Clip the scene at rendering for visualizing the refracted field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06e5f395-3b7a-46d7-a11c-4355dc94f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_gain_db = -130 # in dB; ignore any position with less than -130 dB path gain\n",
    "max_gain_db = 0 # in dB; ignore strong paths\n",
    "\n",
    "# Sample points in a 5-400m range around the receiver\n",
    "min_dist = 1 # in m\n",
    "max_dist = 20 # in m\n",
    "\n",
    "# Sample batch_size random user positions from the radio map\n",
    "ue_pos, _ = rm.sample_positions(num_pos=batch_size_cir,\n",
    "                                metric=\"path_gain\",\n",
    "                                min_val_db=min_gain_db,\n",
    "                                max_val_db=max_gain_db,\n",
    "                                min_dist=min_dist,\n",
    "                                max_dist=max_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3645c60e-e834-4a5c-b209-30f3c834a536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2c9d3df1ce430dae7ed2f49c9ab6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Renderer(camera=PerspectiveCamera(aspect=1.31, children=(DirectionalLight(intensity=0.25, matri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure antenna array for all receivers (=UEs)\n",
    "scene.rx_array = PlanarArray(num_rows=2,\n",
    "                             num_cols= 2,\n",
    "                             vertical_spacing=0.5,\n",
    "                             horizontal_spacing=0.5,\n",
    "                             pattern=\"iso\",\n",
    "                             polarization=\"V\")\n",
    "\n",
    "# Create batch_size receivers\n",
    "for i in range(batch_size_cir):\n",
    "    scene.remove(f\"rx-{i}\") # Remove old receiver if any\n",
    "    rx = Receiver(name=f\"rx-{i}\",\n",
    "                  position=ue_pos[0][i], # Position sampled from radio map\n",
    "                  velocity=(3.,3.,0),\n",
    "                  display_radius=1., # optional, radius of the sphere for visualizing the device\n",
    "                  color=(1,0,0) # optional, color for visualizing the device\n",
    "                  )\n",
    "    scene.add(rx)\n",
    "\n",
    "# And visualize the scene\n",
    "if no_preview:\n",
    "    # Render an image\n",
    "    scene.render(camera=bird_cam,\n",
    "                 radio_map=rm,\n",
    "                 rm_vmin=-110,\n",
    "                 clip_at=2.); # Clip the scene at rendering for visualizing the refracted field\n",
    "else:\n",
    "    # Show preview\n",
    "    scene.preview(radio_map=rm,\n",
    "                  rm_vmin=-110,\n",
    "                  clip_at=2.); # Clip the scene at rendering for visualizing the refracted field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a2050a6-5f12-43f4-aa86-2a28e5cad998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a: (1000, 4, 1, 1, 18, 14)\n",
      "Shape of tau:  (1000, 1, 18)\n",
      "Shape of a: (1, 1, 1000, 4, 18, 14)\n",
      "Shape of tau:  (1, 1000, 18)\n",
      "Shape of a: (874, 1, 1, 1, 4, 18, 14)\n",
      "Shape of tau:  (874, 1, 1, 18)\n"
     ]
    }
   ],
   "source": [
    "target_num_cirs = 500 # Defines how many different CIRs are generated.\n",
    "# Remark: some path are removed if no path was found for this position\n",
    "\n",
    "max_depth = 3\n",
    "min_gain_db = -130 # in dB / ignore any position with less than -130 dB path gain\n",
    "max_gain_db = 0 # in dB / ignore any position with more than 0 dB path gain\n",
    "\n",
    "# Sample points within a 10-400m radius around the transmitter\n",
    "min_dist = 1 # in m\n",
    "max_dist = 20 # in m\n",
    "\n",
    "# List of channel impulse reponses\n",
    "a_list = []\n",
    "tau_list = []\n",
    "\n",
    "# Maximum number of paths over all batches of CIRs.\n",
    "# This is used later to concatenate all CIRs.\n",
    "max_num_paths = 0\n",
    "\n",
    "# Path solver\n",
    "p_solver = PathSolver()\n",
    "\n",
    "# Each simulation returns batch_size_cir results\n",
    "num_runs = int(np.ceil(target_num_cirs/batch_size_cir))\n",
    "for idx in range(num_runs):\n",
    "    print(f\"Progress: {idx+1}/{num_runs}\", end=\"\\r\")\n",
    "\n",
    "    # Sample random user positions\n",
    "    ue_pos, _ = rm.sample_positions(\n",
    "                        num_pos=batch_size_cir,\n",
    "                        metric=\"path_gain\",\n",
    "                        min_val_db=min_gain_db,\n",
    "                        max_val_db=max_gain_db,\n",
    "                        min_dist=min_dist,\n",
    "                        max_dist=max_dist,\n",
    "                        seed=idx) # Change the seed from one run to the next to avoid sampling the same positions\n",
    "\n",
    "    # Update all receiver positions\n",
    "    for rx in range(batch_size_cir):\n",
    "        scene.receivers[f\"rx-{rx}\"].position = ue_pos[0][rx]\n",
    "\n",
    "    # Simulate CIR\n",
    "    paths = p_solver(scene, max_depth=max_depth, max_num_paths_per_src=10**7)\n",
    "\n",
    "    # Transform paths into channel impulse responses\n",
    "    a, tau = paths.cir(sampling_frequency=subcarrier_spacing,\n",
    "                         num_time_steps=14,\n",
    "                         out_type='numpy')\n",
    "    a_list.append(a)\n",
    "    tau_list.append(tau)\n",
    "\n",
    "    # Update maximum number of paths over all batches of CIRs\n",
    "    num_paths = a.shape[-2]\n",
    "    if num_paths > max_num_paths:\n",
    "        max_num_paths = num_paths\n",
    "\n",
    "# Concatenate all the CIRs into a single tensor along the num_rx dimension.\n",
    "# First, we need to pad the CIRs to ensure they all have the same number of paths.\n",
    "a = []\n",
    "tau = []\n",
    "for a_,tau_ in zip(a_list, tau_list):\n",
    "    num_paths = a_.shape[-2]\n",
    "    a.append(np.pad(a_, [[0,0],[0,0],[0,0],[0,0],[0,max_num_paths-num_paths],[0,0]], constant_values=0))\n",
    "    tau.append(np.pad(tau_, [[0,0],[0,0],[0,max_num_paths-num_paths]], constant_values=0))\n",
    "a = np.concatenate(a, axis=0) # Concatenate along the num_rx dimension\n",
    "tau = np.concatenate(tau, axis=0)\n",
    "\n",
    "\n",
    "print(\"Shape of a:\", a.shape)\n",
    "print(\"Shape of tau: \", tau.shape)\n",
    "# Let's now convert to uplink direction, by switing the receiver and transmitter\n",
    "# dimensions\n",
    "a = np.transpose(a, (2,3,0,1,4,5))\n",
    "tau = np.transpose(tau, (1,0,2))\n",
    "print(\"Shape of a:\", a.shape)\n",
    "print(\"Shape of tau: \", tau.shape)\n",
    "# Add a batch_size dimension\n",
    "a = np.expand_dims(a, axis=0)\n",
    "tau = np.expand_dims(tau, axis=0)\n",
    "\n",
    "# Exchange the num_tx and batchsize dimensions\n",
    "a = np.transpose(a, [3, 1, 2, 0, 4, 5, 6])\n",
    "tau = np.transpose(tau, [2, 1, 0, 3])\n",
    "\n",
    "# Remove CIRs that have no active link (i.e., a is all-zero)\n",
    "p_link = np.sum(np.abs(a)**2, axis=(1,2,3,4,5,6))\n",
    "a = a[p_link>0.,...]\n",
    "tau = tau[p_link>0.,...]\n",
    "\n",
    "print(\"Shape of a:\", a.shape)\n",
    "print(\"Shape of tau: \", tau.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "896f7ffb-527e-467b-9cbb-6822319cd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_num_cirs = 5000 # Defines how many different CIRs are generated.\n",
    "# Remark: some path are removed if no path was found for this position\n",
    "\n",
    "max_depth = 5\n",
    "min_gain_db = -130 # in dB / ignore any position with less than -130 dB path gain\n",
    "max_gain_db = 0 # in dB / ignore any position with more than 0 dB path gain\n",
    "\n",
    "# Sample points within a 10-400m radius around the transmitter\n",
    "min_dist = 10 # in m\n",
    "max_dist = 40 # in m\n",
    "\n",
    "# List of channel impulse reponses\n",
    "a_list = []\n",
    "tau_list = []\n",
    "\n",
    "# Maximum number of paths over all batches of CIRs.\n",
    "# This is used later to concatenate all CIRs.\n",
    "max_num_paths = 0\n",
    "\n",
    "# Path solver\n",
    "p_solver = PathSolver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "109fc392-dbd5-49b8-9ec9-7c06d93ac371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750176746.213114    6905 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4560 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20 # Must be the same for the BER simulations as CIRDataset returns fixed batch_size\n",
    "\n",
    "# Init CIR generator\n",
    "cir_generator = CIRGenerator(a,\n",
    "                             tau,\n",
    "                             num_tx)\n",
    "# Initialises a channel model that can be directly used by OFDMChannel layer\n",
    "channel_model = CIRDataset(cir_generator,\n",
    "                           batch_size,\n",
    "                           num_rx,\n",
    "                           num_rx_ant,\n",
    "                           num_tx,\n",
    "                           num_tx_ant,\n",
    "                           max_num_paths,\n",
    "                           num_time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664f775-f650-486a-b877-d8eb30ba7697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
